{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.cluster import adjusted_rand_score,normalized_mutual_info_score,homogeneity_score,contingency_matrix\n",
    "from VGAE_GCN.adj import graph\n",
    "from VGAE_GCN.train_VGAE import train_model\n",
    "from VGAE_GCN.VGAE_model import VGAE\n",
    "from VGAE_GCN.utils import *"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d694c751b19ff9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    cm = contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(cm, axis=0)) / np.sum(cm)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e3b0ec3e663dbe5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed_list = [0]\n",
    " \n",
    "for seed in seed_list:\n",
    "    DLPFC_dir = \"../../../dataset/BRCA1\"\n",
    "    \n",
    "    knn = 20\n",
    "    \n",
    "    ann_data = sc.read_visium(os.path.join(DLPFC_dir,'V1_Human_Breast_Cancer_Block_A_Section_1'))\n",
    "    # load groud truth\n",
    "    ann_df = pd.read_csv(os.path.join(DLPFC_dir,\"metadata.tsv\"),\n",
    "                         sep=\"\\t\", index_col=0)\n",
    "    ann_data.obs.loc[:, \"Manual annotation\"] = ann_df.loc[ann_data.obs_names, 'fine_annot_type']\n",
    "    ann_data.var_names_make_unique()\n",
    "    print(ann_data)\n",
    "    \n",
    "\n",
    "    sc.pp.highly_variable_genes(ann_data, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "    sc.pp.normalize_total(ann_data, target_sum=1e4)\n",
    "    sc.pp.log1p(ann_data)\n",
    "\n",
    "    net = graph(ann_data)\n",
    "    net.compute_spatial_net()\n",
    "    net.Stats_Spatial_Net()\n",
    "\n",
    "    ann_data = train_model(ann_data, input_dim=3000, seed=seed, rad_cutoff=300)\n",
    "\n",
    "    adata = mclust_R(ann_data, used_obsm='z', num_cluster=knn)\n",
    "    indices = np.logical_not(ann_data.obs[\"Manual annotation\"].isna())\n",
    "    ground_truth = ann_data.obs[\"Manual annotation\"].dropna()\n",
    "    mclust_ari = adjusted_rand_score(ann_data.obs['mclust'][indices], ground_truth[indices])\n",
    "    print(\"mclust ari is: {:.4f}\".format(mclust_ari))\n",
    "    mclust_nmi = normalized_mutual_info_score(ann_data.obs['mclust'][indices], ground_truth[indices])\n",
    "    print(\"mclust nmi is: {:.4f}\".format(mclust_nmi))\n",
    "    mclust_hs = homogeneity_score(ann_data.obs['mclust'][indices], ground_truth[indices])\n",
    "    print(\"mclust hs is: {:.4f}\".format(mclust_hs))\n",
    "    mclust_purity = purity_score(ann_data.obs['mclust'][indices], ground_truth[indices])\n",
    "    print(\"mclust purity is: {:.4f}\".format(mclust_purity))\n",
    "\n",
    "    adj_2d = distance.cdist(ann_data.obsm['spatial'], ann_data.obsm['spatial'], 'euclidean')\n",
    "    refined_pred= refine(sample_id=ann_data.obs.index.tolist(), \n",
    "                                 pred=ann_data.obs[\"mclust\"].tolist(), dis=adj_2d, shape=\"hexagon\")\n",
    "    ann_data.obs[\"mclust_refine\"]= refined_pred\n",
    "    indices = np.logical_not(ann_data.obs[\"Manual annotation\"].isna())\n",
    "    ground_truth = ann_data.obs[\"Manual annotation\"].dropna()\n",
    "    mclust_ari = adjusted_rand_score(ann_data.obs['mclust_refine'][indices], ground_truth[indices])\n",
    "    print(\"mclust ari is: {:.4f}\".format(mclust_ari))\n",
    "    mclust_nmi = normalized_mutual_info_score(ann_data.obs['mclust_refine'][indices], ground_truth[indices])\n",
    "    print(\"mclust nmi is: {:.4f}\".format(mclust_nmi))\n",
    "    mclust_hs = homogeneity_score(ann_data.obs['mclust_refine'][indices], ground_truth[indices])\n",
    "    print(\"mclust hs is: {:.4f}\".format(mclust_hs))\n",
    "    mclust_purity = purity_score(ann_data.obs['mclust_refine'][indices], ground_truth[indices])\n",
    "    print(\"mclust purity is: {:.4f}\".format(mclust_purity))\n",
    "    \n",
    "    file = ann_data.obs['mclust_refine']\n",
    "    np.save(os.path.join('result','version_'+str(seed),'pred.npy'),file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b99bedf966b66351"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sc.pl.spatial(ann_data, color='mclust', show=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a67d8a7e404fbad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sc.pp.neighbors(ann_data, use_rep='z', metric='cosine', n_pcs=8)\n",
    "sc.tl.umap(ann_data)\n",
    "\n",
    "\n",
    "sc.pl.umap(ann_data, color='mclust', show=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd22f0f127b60650"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "from typing import List\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "\n",
    "def labels_connectivity_mat(labels: np.ndarray):\n",
    "    _labels = labels - np.min(labels)\n",
    "    n_classes = np.unique(_labels)\n",
    "    mat = np.zeros([labels.size, labels.size])\n",
    "    for i in n_classes:\n",
    "        indices = np.squeeze(np.where(_labels == i))  #将属于各个类的标签提取出来\n",
    "        row_indices, col_indices = zip(*itertools.product(indices, indices))\n",
    "        mat[row_indices, col_indices] = 1\n",
    "    return mat\n",
    "\n",
    "\n",
    "def consensus_matrix(labels_list: List[np.ndarray]):\n",
    "    mat = 0\n",
    "    for labels in labels_list:\n",
    "        mat += labels_connectivity_mat(labels)\n",
    "    return mat / float(len(labels_list))\n",
    "\n",
    "\n",
    "def plot_consensus_map(cmat, method=\"average\", return_linkage=True, **kwargs):\n",
    "    row_linkage = hierarchy.linkage(distance.pdist(cmat), method=method)\n",
    "    col_linkage = hierarchy.linkage(distance.pdist(cmat.T), method=method)\n",
    "    figure = sns.clustermap(cmat, row_linkage=row_linkage, col_linkage=col_linkage, **kwargs)\n",
    "    if return_linkage:\n",
    "        return row_linkage, col_linkage, figure\n",
    "    else:\n",
    "        return figure"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b01d904b3ddb301"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_dir = os.path.join('result')\n",
    "name = \"pred.npy\"\n",
    "num_cluster = knn\n",
    "\n",
    "sys.setrecursionlimit(100000)\n",
    "label_files = glob.glob(save_dir + f\"/version_*/{name}\")\n",
    "labels_list = list(map(lambda file: np.load(file), label_files))\n",
    "cons_mat = consensus_matrix(labels_list)\n",
    "row_linkage, _, figure = plot_consensus_map(cons_mat, return_linkage=True)  # 获取层次聚类结果和热度图\n",
    "figure.savefig(os.path.join(save_dir, \"consensus_clustering.png\"), dpi=300)  # 保存图片\n",
    "consensus_labels = hierarchy.cut_tree(row_linkage, num_cluster).squeeze()  # 得到y*\n",
    "np.save(os.path.join(save_dir, \"consensus_labels\"), consensus_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c6e9e72b12c7dc2e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = np.load(os.path.join('result','consensus_labels.npy'))\n",
    "indices = np.logical_not(ann_data.obs[\"Manual annotation\"].isna())\n",
    "ground_truth = ann_data.obs[\"Manual annotation\"].dropna()\n",
    "ari = adjusted_rand_score(pred[indices], ground_truth[indices])\n",
    "print(\"ari is: {:.4f}\".format(ari))\n",
    "nmi = normalized_mutual_info_score(pred[indices], ground_truth[indices])\n",
    "print(\"nmi is: {:.4f}\".format(nmi))\n",
    "hs = homogeneity_score(pred[indices], ground_truth[indices])\n",
    "print(\"hs is: {:.4f}\".format(hs))\n",
    "purity = purity_score(pred[indices], ground_truth[indices])\n",
    "print(\"purity is: {:.4f}\".format(purity))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "478ab0ec46fe1263"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "358c9540b9fba4a1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
